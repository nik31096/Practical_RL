{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-Critic for MountainCar-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ### Actor-Critic for MountainCar-v0\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "s = env.reset()\n",
    "\n",
    "obs_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Preprocessing: Normalize to zero mean and unit variance\n",
    "# We use a few samples from the observation space to do this\n",
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "# Used to converte a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(observation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_state(state):\n",
    "    \"\"\"\n",
    "    Returns the featurized representation for a state.\n",
    "    \"\"\"\n",
    "    scaled = scaler.transform([state])\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized[0]\n",
    "\n",
    "\n",
    "featured_shape = featurize_state(s).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.dense1 = nn.Linear(featured_shape, 200)\n",
    "        self.dense2 = nn.Linear(200, n_actions)\n",
    "        self.dense3 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.FloatTensor(featurize_state(x))\n",
    "        x = self.dense1(x)\n",
    "        x = F.relu(x)\n",
    "        logits = self.dense2(x)\n",
    "        values = self.dense3(x)\n",
    "\n",
    "        return logits, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where(cond, x1, x2):\n",
    "    return (1 - cond)*x1 + cond*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "opt = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
    "rewards = []\n",
    "actorLoss = []\n",
    "criticLoss = []\n",
    "Entropy = []\n",
    "state = env.reset()\n",
    "for i_episode in range(100000):\n",
    "    logits, values = agent(state)\n",
    "    policy = F.softmax(logits)\n",
    "    log_policy = F.log_softmax(logits)\n",
    "    action = np.random.choice(n_actions, p=policy.data.numpy())\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    reward = torch.FloatTensor([reward])\n",
    "\n",
    "    _, next_values = agent(next_state)\n",
    "    # actor\n",
    "    entropy = -torch.mean(policy * log_policy)\n",
    "    advantage = reward + gamma * next_values - torch.squeeze(values)\n",
    "    advantage = reward if not done else reward + gamma * next_values - torch.squeeze(values)\n",
    "    actor_loss = -0.01 * entropy - torch.mean(advantage.detach() * log_policy[action])\n",
    "    # critic\n",
    "    td_target = reward + gamma * next_values.detach() if not done else reward\n",
    "    critic_loss = torch.mean((td_target - values) ** 2)\n",
    "\n",
    "    rewards.append(reward)\n",
    "    loss = actor_loss + critic_loss\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        continue\n",
    "    if i_episode % 1000 == 0:\n",
    "        clear_output(True)\n",
    "        actorLoss.append(actor_loss.data.numpy())\n",
    "        criticLoss.append(critic_loss.data.numpy())\n",
    "        Entropy.append(entropy.data.numpy())\n",
    "        print(\"episode: {}, reward: {}\".format(i_episode + 1, np.mean(rewards[-10:])))\n",
    "        print(\"Critic loss:\", criticLoss[-1], \"Actor loss:\", actorLoss[-1])\n",
    "        plt.subplot(131)\n",
    "        plt.plot(criticLoss)\n",
    "        plt.title(\"Critic loss\")\n",
    "        plt.subplot(132)\n",
    "        plt.plot(actorLoss)\n",
    "        plt.title(\"Actor loss\")\n",
    "        plt.subplot(133)\n",
    "        plt.plot(Entropy)\n",
    "        plt.title(\"Entropy\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-critic for MountainCarContinuous-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link on tensorflow implementation of A2C for MountainCarContinuous-v0\n",
    "https://github.com/dennybritz/reinforcement-learning/blob/master/PolicyGradient/Continuous%20MountainCar%20Actor%20Critic%20Solution.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCarContinuous-v0\")\n",
    "s = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_shape = env.observation_space.shape\n",
    "action_shape = env.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.dense1 = nn.Linear(obs_shape[0], 200) \n",
    "        self.dense2 = nn.Linear(200, 1)\n",
    "        self.dense3 = nn.Linear(200, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        x = F.tanh(self.dense1(x))\n",
    "        self.mu = self.dense2(x)\n",
    "        self.sigma = self.dense3(x)\n",
    "        \n",
    "        self.mu = torch.squeeze(self.mu)\n",
    "        self.sigma = F.softplus(torch.squeeze(self.sigma)) + 1e-5\n",
    "        self.normal = torch.distributions.normal.Normal(self.mu, self.sigma)\n",
    "        actions = self.normal.sample(sample_shape=torch.Size(action_shape))\n",
    "        actions = torch.clamp(actions, env.action_space.low[0], env.action_space.high[0])\n",
    "        return actions\n",
    "    \n",
    "    def get_entropy(self):\n",
    "        return self.normal.entropy()\n",
    "    \n",
    "    def get_log_prob(self, action):\n",
    "        return self.normal.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        self.dense1 = nn.Linear(obs_shape[0], 200)\n",
    "        self.dense2 = nn.Linear(200, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        x = F.tanh(self.dense1(x))\n",
    "        v_s = self.dense2(x)\n",
    "        \n",
    "        return v_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_estimator = PolicyNetwork().to(device)\n",
    "policy_estimator([s]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_estimator = ValueNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(tmax=1000):\n",
    "    states, actions, rewards, dones, next_states = [], [], [], [], []\n",
    "    s = env.reset()\n",
    "    for i in range(tmax):\n",
    "        action = policy_estimator([s])\n",
    "        new_s, reward, done, info = env.step(action.cpu().data.numpy())\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "        states.append(s)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        dones.append(done)\n",
    "        next_states.append(new_s)\n",
    "        s = new_s\n",
    "        \n",
    "    return states, actions, rewards, dones, next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, dones, next_states = generate_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_critic_loss(optimizer, states, rewards, next_states, gamma):\n",
    "    states = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "    next_states = torch.tensor(next_states.astype('float'), dtype=torch.float32).to(device)\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "    next_v_s = value_estimator(next_states).detach()\n",
    "    td_target = rewards + gamma*next_v_s\n",
    "    td_error = (td_target - value_estimator(states))**2\n",
    "    loss = torch.mean(td_error)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return loss.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actor_loss(optimizer, states, actions, rewards, next_states, gamma):\n",
    "    H = policy_estimator.get_entropy()\n",
    "    states = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "    actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "    next_states = torch.tensor(next_states.astype('float'), dtype=torch.float32)\n",
    "    td_target = rewards + gamma*value_estimator(next_states)\n",
    "    td_error = td_target - value_estimator(states)\n",
    "    loss = -0.1*H - policy_estimator.get_log_prob(actions)*td_error.detach()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return loss.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gamma=0.99, episodes=10, tmax=1000):\n",
    "    opt = torch.optim.Adam(list(policy_estimator.parameters()) + list(value_estimator.parameters()), lr=1e-3)\n",
    "    rewards = []\n",
    "    loss_values_L = []\n",
    "    loss_values_J = []\n",
    "    for i_episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_rewards = []\n",
    "        \n",
    "        for t in range(tmax):\n",
    "            \n",
    "            action = policy_estimator(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_rewards.append(reward)\n",
    "            \n",
    "            Ltd = compute_critic_loss(opt, state, reward, next_state, gamma)\n",
    "            \n",
    "            J = compute_actor_loss(opt, state, action, reward, next_state, gamma)\n",
    "            if t % 500 == 0:\n",
    "                loss_values_J.append(J)\n",
    "                loss_values_L.append(Ltd)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        rewards.append(np.mean(np.array(episode_rewards)))\n",
    "        clear_output(True)\n",
    "        print(\"episode: {}, reward: {}\".format(i_episode + 1, np.mean(np.array(episode_rewards))))\n",
    "        print(loss_values_J[-1])\n",
    "        plt.subplot(121)\n",
    "        plt.plot(loss_values_L)\n",
    "        plt.title(\"Ltd loss\")\n",
    "        plt.subplot(122)\n",
    "        plt.plot(loss_values_J)\n",
    "        plt.title(\"J_hat loss\")\n",
    "        plt.show()\n",
    "        \n",
    "    return np.array(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = torch.distributions.normal.Normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4189)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10, reward: -0.0004209252504765729\n",
      "[-0.46652836]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-3.51630868e-02, -1.68083060e-02, -7.01596445e-03, -2.37690489e-03,\n",
       "       -6.90292012e-04, -3.27295153e-04, -8.47560537e-05, -3.29564471e-04,\n",
       "       -2.02674452e-04, -4.20925250e-04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for t in range(1000):\n",
    "    action = policy_estimator(state).to('cpu')\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    state = next_state\n",
    "    env.render()\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
